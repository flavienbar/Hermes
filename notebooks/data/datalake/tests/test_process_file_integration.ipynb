{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af254ba1",
   "metadata": {},
   "source": [
    "# üß™ Notebook d'Int√©gration : Validation de `process_file`\n",
    "\n",
    "Ce notebook ex√©cute une batterie de tests d'int√©gration sur la m√©thode `process_file` de `BinanceDataProcessorV2`.\n",
    "\n",
    "Objectifs:\n",
    "- V√©rifier la d√©tection des unit√©s de timestamps (s / ms / ¬µs)\n",
    "- V√©rifier l'idempotence (OVERWRITE_OR_IGNORE)\n",
    "- V√©rifier le partitionnement year/month/day\n",
    "- V√©rifier la pr√©sence et le format de `ingest_id`\n",
    "- V√©rifier la robustesse face aux archives corrompues ou invalides\n",
    "- Mesurer des m√©triques simples de performance\n",
    "- Produire un rapport r√©capitulatif final\n",
    "\n",
    "---\n",
    "Ex√©cution : la derni√®re cellule orchestre tous les tests automatiquement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cdd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Param√®tres de Test\n",
    "import os, io, zipfile, datetime, tempfile, shutil, random, time, re\n",
    "from pathlib import Path\n",
    "import duckdb, polars as pl\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "pl.Config.set_tbl_rows(30)\n",
    "\n",
    "USE_MINIO = bool(int(os.getenv('USE_MINIO', '0')))\n",
    "RUN_ID = datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%S')\n",
    "print(f\"USE_MINIO={USE_MINIO} | RUN_ID={RUN_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chargement / D√©finition de la classe cible\n",
    "try:\n",
    "    from pipeline.binance import BinanceDataProcessorV2  # type: ignore\n",
    "    CLASS_IMPORTED = True\n",
    "except Exception:\n",
    "    CLASS_IMPORTED = False\n",
    "    import duckdb, polars as pl, datetime, zipfile\n",
    "    class BinanceDataProcessorV2:\n",
    "        def __init__(self, config: dict):\n",
    "            self.config = config\n",
    "            self.csv_columns = [\n",
    "                'open_time','open','high','low','close','volume','close_time',\n",
    "                'quote_asset_volume','number_of_trades','taker_buy_base_volume',\n",
    "                'taker_buy_quote_volume','ignore'\n",
    "            ]\n",
    "            self.errors = []\n",
    "            self.processed_files = 0\n",
    "        def setup_duckdb_connection(self):\n",
    "            con = duckdb.connect(database=':memory:')\n",
    "            con.execute(f\"\"\"\n",
    "                SET s3_access_key_id='{self.config.get('minio_access_key','')}';\n",
    "                SET s3_secret_access_key='{self.config.get('minio_secret_key','')}';\n",
    "                SET s3_endpoint='{self.config.get('minio_endpoint','')}';\n",
    "                SET s3_url_style='path';\n",
    "                SET s3_use_ssl='false';\n",
    "            \"\"\")\n",
    "            return con\n",
    "        def process_file(self, zip_path: Path, con: duckdb.DuckDBPyConnection, output_path: str):\n",
    "            try:\n",
    "                with zipfile.ZipFile(str(zip_path)) as z:\n",
    "                    csv_candidates = [n for n in z.namelist() if n.lower().endswith('.csv')]\n",
    "                    if not csv_candidates:\n",
    "                        raise ValueError('Aucun CSV dans le zip')\n",
    "                    csv_name = csv_candidates[0]\n",
    "                    with z.open(csv_name) as f:\n",
    "                        df = pl.read_csv(f, has_header=False, new_columns=self.csv_columns)\n",
    "                df = df.with_columns([\n",
    "                    pl.col('open_time').cast(pl.Int64, strict=False),\n",
    "                    pl.col('close_time').cast(pl.Int64, strict=False),\n",
    "                ])\n",
    "                first_ts = df.select(pl.col('open_time').first()).item()\n",
    "                if first_ts > 10_000_000_000_000:\n",
    "                    ts_col = (pl.col('open_time') // 1000).cast(pl.Datetime('ms'))\n",
    "                elif first_ts > 10_000_000_000:\n",
    "                    ts_col = pl.col('open_time').cast(pl.Datetime('ms'))\n",
    "                else:\n",
    "                    ts_col = (pl.col('open_time') * 1000).cast(pl.Datetime('ms'))\n",
    "                ingest_id = datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%SZ') + '_' + zip_path.name\n",
    "                df = df.with_columns([\n",
    "                    ts_col.alias('datetime'),\n",
    "                    pl.lit(ingest_id).alias('ingest_id'),\n",
    "                ]).with_columns([\n",
    "                    pl.col('datetime').dt.year().alias('year'),\n",
    "                    pl.col('datetime').dt.month().alias('month'),\n",
    "                    pl.col('datetime').dt.day().alias('day'),\n",
    "                ])\n",
    "                con.register('tmp_data', df.to_arrow())\n",
    "                sql = f\"\"\"\n",
    "                    COPY tmp_data\n",
    "                    TO '{output_path}'\n",
    "                    WITH (FORMAT PARQUET, PARTITION_BY (year, month, day), OVERWRITE_OR_IGNORE TRUE)\n",
    "                \"\"\"\n",
    "                con.execute(sql)\n",
    "                try: con.execute(\"DROP VIEW IF EXISTS tmp_data\")\n",
    "                except: pass\n",
    "                self.processed_files += 1\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                self.errors.append({'file': zip_path.name, 'error': str(e)})\n",
    "                try: con.execute(\"DROP VIEW IF EXISTS tmp_data\")\n",
    "                except: pass\n",
    "                return False\n",
    "print('Classe import√©e:' , CLASS_IMPORTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration Backend (MinIO ou FS Local)\n",
    "from typing import Tuple\n",
    "try:\n",
    "    from minio import Minio\n",
    "except ImportError:\n",
    "    Minio = None\n",
    "\n",
    "def build_output_path():\n",
    "    if USE_MINIO:\n",
    "        return f\"s3://bronze/binance/data/spot/monthly/klines/BTCUSDT/4h/test_int_{RUN_ID}/\"\n",
    "    else:\n",
    "        return str((TMP_BASE / 'bronze' / 'binance' / 'data' / 'spot' / 'monthly' / 'klines' / 'BTCUSDT' / '4h' / f'test_int_{RUN_ID}' / ''))\n",
    "\n",
    "if not USE_MINIO:\n",
    "    TMP_BASE = Path(tempfile.mkdtemp(prefix='process_file_it_'))\n",
    "    (TMP_BASE / 'bronze').mkdir(parents=True, exist_ok=True)\n",
    "    print('R√©pertoire local de test:', TMP_BASE)\n",
    "else:\n",
    "    assert Minio is not None, 'minio package requis pour USE_MINIO=1'\n",
    "    MINIO_ENDPOINT = os.getenv('MINIO_ENDPOINT','127.0.0.1:9000')\n",
    "    MINIO_ACCESS_KEY = os.getenv('MINIO_ROOT_USER','minioadm')\n",
    "    MINIO_SECRET_KEY = os.getenv('MINIO_ROOT_PASSWORD','minioadm')\n",
    "    minio_client = Minio(MINIO_ENDPOINT, access_key=MINIO_ACCESS_KEY, secret_key=MINIO_SECRET_KEY, secure=False)\n",
    "    if not minio_client.bucket_exists('bronze'):\n",
    "        minio_client.make_bucket('bronze')\n",
    "    print('Bucket bronze OK')\n",
    "\n",
    "OUTPUT_PATH = build_output_path()\n",
    "print('OUTPUT_PATH =', OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Utilitaires: G√©n√©ration OHLCV synth√©tiques\n",
    "\n",
    "def make_ohlcv_df(n_rows: int, start_ts_ms: int, step_ms: int) -> pl.DataFrame:\n",
    "    rows = []\n",
    "    for i in range(n_rows):\n",
    "        ot = start_ts_ms + i * step_ms\n",
    "        row = [\n",
    "            ot,                # open_time\n",
    "            100 + i * 0.1,     # open\n",
    "            100 + i * 0.15,    # high\n",
    "            100 + i * 0.05,    # low\n",
    "            100 + i * 0.12,    # close\n",
    "            10 + i,            # volume\n",
    "            ot + step_ms,      # close_time\n",
    "            1000 + i,          # quote_asset_volume\n",
    "            50 + i,            # number_of_trades\n",
    "            5 + i * 0.1,       # taker_buy_base_volume\n",
    "            500 + i,           # taker_buy_quote_volume\n",
    "            0                  # ignore\n",
    "        ]\n",
    "        rows.append(row)\n",
    "    return pl.DataFrame(rows, schema=[\n",
    "        'open_time','open','high','low','close','volume','close_time',\n",
    "        'quote_asset_volume','number_of_trades','taker_buy_base_volume',\n",
    "        'taker_buy_quote_volume','ignore'\n",
    "    ])\n",
    "\n",
    "# 5. Utilitaires: Cr√©ation ZIP test\n",
    "def build_zip(df: pl.DataFrame, ts_unit: str, dest_zip: Path) -> Path:\n",
    "    conv = df.clone()\n",
    "    if ts_unit == 's':\n",
    "        conv = conv.with_columns((pl.col('open_time') // 1000).alias('open_time'))\n",
    "        conv = conv.with_columns((pl.col('close_time') // 1000).alias('close_time'))\n",
    "    elif ts_unit == 'ms':\n",
    "        pass\n",
    "    elif ts_unit == 'us':\n",
    "        conv = conv.with_columns((pl.col('open_time') * 1000).alias('open_time'))\n",
    "        conv = conv.with_columns((pl.col('close_time') * 1000).alias('close_time'))\n",
    "    else:\n",
    "        raise ValueError('ts_unit invalide')\n",
    "    csv_bytes = io.StringIO()\n",
    "    conv.write_csv(csv_bytes, include_header=False)\n",
    "    csv_bytes.seek(0)\n",
    "    with zipfile.ZipFile(dest_zip, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        z.writestr('BTCUSDT-4h-test.csv', csv_bytes.getvalue())\n",
    "    return dest_zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fixture: init environnement\n",
    "\n",
    "def init_env():\n",
    "    config = {\n",
    "        'provider':'binance','data_type':'data','market':'spot','data_frequency':'monthly',\n",
    "        'data_category':'klines','symbol':'BTCUSDT','interval':'4h',\n",
    "        'minio_access_key': os.getenv('MINIO_ROOT_USER','minioadm'),\n",
    "        'minio_secret_key': os.getenv('MINIO_ROOT_PASSWORD','minioadm'),\n",
    "        'minio_endpoint': os.getenv('MINIO_ENDPOINT','127.0.0.1:9000')\n",
    "    }\n",
    "    processor = BinanceDataProcessorV2(config)\n",
    "    con = processor.setup_duckdb_connection()\n",
    "    return processor, con, OUTPUT_PATH\n",
    "\n",
    "processor, con, OUTPUT_PATH = init_env()\n",
    "print('Environnement initialis√©')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
