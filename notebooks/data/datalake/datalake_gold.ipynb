{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15058e2",
   "metadata": {},
   "source": [
    "# ü•á Data Lakehouse Gold - Feature Store Optimis√©\n",
    "\n",
    "## 1. Introduction & Architecture\n",
    "\n",
    "Ce notebook impl√©mente la **zone Gold** de notre data lakehouse avec une approche **Feature Store** optimis√©e :\n",
    "\n",
    "### üèóÔ∏è **Architecture Gold**\n",
    "\n",
    "1. **üìä Feature Store Central** : `gold_features_crypto_4h`\n",
    "   - Table unique contenant tous les indicateurs techniques pr√©-calcul√©s\n",
    "   - Source de v√©rit√© pour tous les features r√©utilisables\n",
    "   - Format : 1 ligne = 1 crypto + 1 timestamp + tous les indicateurs\n",
    "\n",
    "2. **üéØ Marts de Strat√©gies** : `gold_strategy_{nom_strategie}`\n",
    "   - Tables sp√©cialis√©es contenant les signaux de trading\n",
    "   - Consomment les features du Feature Store\n",
    "   - Une table par strat√©gie pour la flexibilit√©\n",
    "\n",
    "### ‚ú® **Avantages**\n",
    "\n",
    "- **üöÄ Performance** : Calcul unique des indicateurs (DRY principle)\n",
    "- **‚ö° Rapidit√©** : Prototypage instantan√© de nouvelles strat√©gies  \n",
    "- **üîÑ R√©utilisabilit√©** : Features partag√©s entre strat√©gies\n",
    "- **üìà √âvolutivit√©** : Ajout facile de nouveaux indicateurs\n",
    "- **üîß Traitement Incr√©mental** : Lookback intelligent pour tous les indicateurs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fe641",
   "metadata": {},
   "source": [
    "## 2. Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6579c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e\n",
      "üìä Source Bronze: s3://bronze/binance/data/spot/monthly/klines/BTCUSDT/4h/**/*.parquet\n",
      "ü•á Destination Gold: s3://gold\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import talib as ta\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration globale\n",
    "class Config:\n",
    "    \"\"\"Configuration centralis√©e pour le pipeline Gold\"\"\"\n",
    "    \n",
    "    # MinIO/S3 Configuration\n",
    "    MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"127.0.0.1:9000\")\n",
    "    MINIO_ACCESS_KEY = os.getenv(\"MINIO_ROOT_USER\", \"minioadm\")\n",
    "    MINIO_SECRET_KEY = os.getenv(\"MINIO_ROOT_PASSWORD\", \"minioadm\")\n",
    "    \n",
    "    # Chemins de donn√©es\n",
    "    medaillon_source = \"bronze\"\n",
    "    provider = \"binance\"\n",
    "    data_type = \"data\"\n",
    "    market = \"spot\"\n",
    "    data_frequency = \"monthly\"\n",
    "    data_category = \"klines\"\n",
    "    symbol = \"BTCUSDT\"\n",
    "    interval = \"4h\"\n",
    "    BRONZE_PATH = f\"s3://{medaillon_source}/{provider}/{data_type}/{market}/{data_frequency}/{data_category}/{symbol}/{interval}/**/*.parquet\"\n",
    "    GOLD_BUCKET = \"s3://gold\"\n",
    "    \n",
    "    # Tables Gold\n",
    "    FEATURE_STORE_TABLE = f\"gold_features_{market}_{data_frequency}_{data_category}_{symbol}_{interval}\"\n",
    "    \n",
    "    # Param√®tres des indicateurs techniques\n",
    "    TECHNICAL_INDICATORS = {\n",
    "        \"sma_periods\": [10, 20, 50, 100, 200],\n",
    "        \"ema_periods\": [12, 20, 26, 50, 100],\n",
    "        \"rsi_periods\": [14, 21],\n",
    "        \"bollinger\": {\"period\": 20, \"std_dev\": 2},\n",
    "        \"macd\": {\"fast\": 12, \"slow\": 26, \"signal\": 9},\n",
    "        \"atr_period\": 14,\n",
    "        \"supertrend\": {\"length\": 10, \"multiplier\": 3.0},\n",
    "        \"stochastic\": {\"k_period\": 14, \"d_period\": 3}\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e\")\n",
    "print(f\"üìä Source Bronze: {Config.BRONZE_PATH}\")\n",
    "print(f\"ü•á Destination Gold: {Config.GOLD_BUCKET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ec8bd",
   "metadata": {},
   "source": [
    "## 3. Feature Store Optimis√© avec Traitement Incr√©mental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dae99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature Store OPTIMIS√â initialis√©\n"
     ]
    }
   ],
   "source": [
    "class UltraFixedIncrementalFeatureStore:\n",
    "    \"\"\"Feature Store OPTIMIS√â avec lookback intelligent pour TOUS les indicateurs\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.con = None\n",
    "    \n",
    "    def setup_duckdb(self):\n",
    "        \"\"\"Configure DuckDB avec les param√®tres S3/MinIO\"\"\"\n",
    "        self.con = duckdb.connect(database=\":memory:\")\n",
    "        self.con.execute(f\"\"\"\n",
    "            SET s3_access_key_id='{self.config.MINIO_ACCESS_KEY}';\n",
    "            SET s3_secret_access_key='{self.config.MINIO_SECRET_KEY}';\n",
    "            SET s3_endpoint='{self.config.MINIO_ENDPOINT}';\n",
    "            SET s3_url_style='path';\n",
    "            SET s3_use_ssl='false';\n",
    "        \"\"\")\n",
    "        print(\"üîó DuckDB configur√© pour MinIO\")\n",
    "    \n",
    "    def load_bronze_data(self, start_date: str = None) -> pl.DataFrame:\n",
    "        \"\"\"Charge les donn√©es depuis la zone Bronze avec filtre optionnel\"\"\"\n",
    "        print(\"üì• Chargement des donn√©es Bronze...\")\n",
    "        \n",
    "        where_clause = \"\"\n",
    "        if start_date:\n",
    "            where_clause = f\"WHERE datetime >= '{start_date}'\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                datetime,\n",
    "                open,\n",
    "                high,\n",
    "                low,\n",
    "                close,\n",
    "                volume,\n",
    "                year,\n",
    "                month,\n",
    "                day\n",
    "            FROM read_parquet('{self.config.BRONZE_PATH}')\n",
    "            {where_clause}\n",
    "            ORDER BY datetime\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pl.from_arrow(self.con.execute(query).arrow())\n",
    "        \n",
    "        print(f\"‚úÖ {df.height:,} lignes charg√©es de Bronze\")\n",
    "        if df.height > 0:\n",
    "            print(f\"üìÖ P√©riode: {df['datetime'].min()} ‚Üí {df['datetime'].max()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_technical_indicators(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Calcule TOUS les indicateurs techniques de mani√®re optimis√©e\"\"\"\n",
    "        print(\"üîß Calcul des indicateurs techniques...\")\n",
    "        \n",
    "        # Conversion en numpy pour TA-Lib\n",
    "        ohlcv = {\n",
    "            'open': df['open'].to_numpy(),\n",
    "            'high': df['high'].to_numpy(), \n",
    "            'low': df['low'].to_numpy(),\n",
    "            'close': df['close'].to_numpy(),\n",
    "            'volume': df['volume'].to_numpy()\n",
    "        }\n",
    "        \n",
    "        indicators = {}\n",
    "        \n",
    "        # 1. Moyennes Mobiles Simples (SMA)\n",
    "        for period in self.config.TECHNICAL_INDICATORS['sma_periods']:\n",
    "            indicators[f'sma_{period}'] = ta.SMA(ohlcv['close'], timeperiod=period)\n",
    "        \n",
    "        # 2. Moyennes Mobiles Exponentielles (EMA) \n",
    "        for period in self.config.TECHNICAL_INDICATORS['ema_periods']:\n",
    "            indicators[f'ema_{period}'] = ta.EMA(ohlcv['close'], timeperiod=period)\n",
    "        \n",
    "        # 3. RSI (Relative Strength Index)\n",
    "        for period in self.config.TECHNICAL_INDICATORS['rsi_periods']:\n",
    "            indicators[f'rsi_{period}'] = ta.RSI(ohlcv['close'], timeperiod=period)\n",
    "        \n",
    "        # 4. Bollinger Bands\n",
    "        bb_params = self.config.TECHNICAL_INDICATORS['bollinger']\n",
    "        bb_upper, bb_middle, bb_lower = ta.BBANDS(\n",
    "            ohlcv['close'], \n",
    "            timeperiod=bb_params['period'], \n",
    "            nbdevup=bb_params['std_dev'],\n",
    "            nbdevdn=bb_params['std_dev']\n",
    "        )\n",
    "        indicators[f\"bb_upper_{bb_params['period']}_{bb_params['std_dev']}\"] = bb_upper\n",
    "        indicators[f\"bb_middle_{bb_params['period']}_{bb_params['std_dev']}\"] = bb_middle\n",
    "        indicators[f\"bb_lower_{bb_params['period']}_{bb_params['std_dev']}\"] = bb_lower\n",
    "        \n",
    "        # 5. MACD\n",
    "        macd_params = self.config.TECHNICAL_INDICATORS['macd']\n",
    "        macd_line, macd_signal, macd_hist = ta.MACD(\n",
    "            ohlcv['close'],\n",
    "            fastperiod=macd_params['fast'],\n",
    "            slowperiod=macd_params['slow'], \n",
    "            signalperiod=macd_params['signal']\n",
    "        )\n",
    "        indicators[f\"macd_{macd_params['fast']}_{macd_params['slow']}_{macd_params['signal']}\"] = macd_line\n",
    "        indicators[f\"macd_signal_{macd_params['fast']}_{macd_params['slow']}_{macd_params['signal']}\"] = macd_signal\n",
    "        indicators[f\"macd_hist_{macd_params['fast']}_{macd_params['slow']}_{macd_params['signal']}\"] = macd_hist\n",
    "        \n",
    "        # 6. ATR (Average True Range)\n",
    "        atr_period = self.config.TECHNICAL_INDICATORS['atr_period']\n",
    "        indicators[f'atr_{atr_period}'] = ta.ATR(\n",
    "            ohlcv['high'], ohlcv['low'], ohlcv['close'], timeperiod=atr_period\n",
    "        )\n",
    "        \n",
    "        # 7. Stochastic Oscillator\n",
    "        stoch_params = self.config.TECHNICAL_INDICATORS['stochastic']\n",
    "        stoch_k, stoch_d = ta.STOCH(\n",
    "            ohlcv['high'], ohlcv['low'], ohlcv['close'],\n",
    "            fastk_period=stoch_params['k_period'],\n",
    "            slowk_period=stoch_params['d_period'],\n",
    "            slowd_period=stoch_params['d_period']\n",
    "        )\n",
    "        indicators[f\"stoch_k_{stoch_params['k_period']}_{stoch_params['d_period']}\"] = stoch_k\n",
    "        indicators[f\"stoch_d_{stoch_params['k_period']}_{stoch_params['d_period']}\"] = stoch_d\n",
    "        \n",
    "        # 8. SuperTrend (impl√©mentation native) - VERSION CORRIG√âE\n",
    "        try:\n",
    "            st_params = self.config.TECHNICAL_INDICATORS['supertrend']\n",
    "            \n",
    "            # Calcul SuperTrend natif avec TA-Lib\n",
    "            supertrend_values, supertrend_direction = self._calculate_supertrend_native(\n",
    "                high=ohlcv['high'],\n",
    "                low=ohlcv['low'],\n",
    "                close=ohlcv['close'],\n",
    "                length=st_params['length'],\n",
    "                multiplier=st_params['multiplier']\n",
    "            )\n",
    "            \n",
    "            indicators[f\"supertrend_{st_params['length']}_{st_params['multiplier']}\"] = supertrend_values\n",
    "            indicators[f\"supertrend_dir_{st_params['length']}_{st_params['multiplier']}\"] = supertrend_direction\n",
    "            \n",
    "            print(f\"‚úÖ SuperTrend calcul√© avec impl√©mentation native\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur SuperTrend: {e}\")\n",
    "            # Cr√©er des arrays de NaN de la bonne taille en cas d'erreur\n",
    "            nan_array = np.full(len(df), np.nan)\n",
    "            indicators[f\"supertrend_{st_params['length']}_{st_params['multiplier']}\"] = nan_array\n",
    "            indicators[f\"supertrend_dir_{st_params['length']}_{st_params['multiplier']}\"] = nan_array\n",
    "        \n",
    "        # Ajout des indicateurs au DataFrame\n",
    "        indicator_columns = []\n",
    "        for name, values in indicators.items():\n",
    "            indicator_columns.append(pl.Series(name=name, values=values))\n",
    "        \n",
    "        df_with_indicators = df.with_columns(indicator_columns)\n",
    "        \n",
    "        print(f\"‚úÖ {len(indicators)} indicateurs calcul√©s\")\n",
    "        return df_with_indicators\n",
    "    \n",
    "    def _calculate_supertrend_native(self, high, low, close, length=10, multiplier=3.0):\n",
    "        \"\"\"\n",
    "        Calcule SuperTrend de mani√®re native avec TA-Lib\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (supertrend_values, supertrend_direction)\n",
    "                - supertrend_values: Les valeurs SuperTrend\n",
    "                - supertrend_direction: 1 pour bullish, -1 pour bearish\n",
    "        \"\"\"\n",
    "        # 1. Calcul de l'ATR avec TA-Lib\n",
    "        atr = ta.ATR(high, low, close, timeperiod=length)\n",
    "        \n",
    "        # 2. Calcul des bandes haute et basse\n",
    "        hl2 = (high + low) / 2.0  # M√©diane high-low\n",
    "        upper_band = hl2 + (multiplier * atr)\n",
    "        lower_band = hl2 - (multiplier * atr)\n",
    "        \n",
    "        # 3. Initialisation des arrays\n",
    "        n = len(close)\n",
    "        supertrend = np.full(n, np.nan)\n",
    "        direction = np.full(n, np.nan, dtype=float)\n",
    "        \n",
    "        # 4. Initialisation des bandes finales\n",
    "        final_upper = np.copy(upper_band)\n",
    "        final_lower = np.copy(lower_band)\n",
    "        \n",
    "        # 5. Calcul it√©ratif du SuperTrend\n",
    "        # Commencer apr√®s la p√©riode ATR\n",
    "        start_idx = length\n",
    "        \n",
    "        for i in range(start_idx, n):\n",
    "            if np.isnan(atr[i]) or np.isnan(upper_band[i]) or np.isnan(lower_band[i]):\n",
    "                continue\n",
    "                \n",
    "            # Calcul des bandes finales (√† partir du 2√®me √©l√©ment valide)\n",
    "            if i > start_idx:\n",
    "                # Bande sup√©rieure finale\n",
    "                if upper_band[i] < final_upper[i-1] or close[i-1] > final_upper[i-1]:\n",
    "                    final_upper[i] = upper_band[i]\n",
    "                else:\n",
    "                    final_upper[i] = final_upper[i-1]\n",
    "                \n",
    "                # Bande inf√©rieure finale  \n",
    "                if lower_band[i] > final_lower[i-1] or close[i-1] < final_lower[i-1]:\n",
    "                    final_lower[i] = lower_band[i]\n",
    "                else:\n",
    "                    final_lower[i] = final_lower[i-1]\n",
    "            \n",
    "            # D√©termination de la direction et SuperTrend\n",
    "            if i == start_idx:\n",
    "                # Premier calcul valide\n",
    "                if close[i] <= final_lower[i]:\n",
    "                    direction[i] = -1.0\n",
    "                    supertrend[i] = final_upper[i]\n",
    "                else:\n",
    "                    direction[i] = 1.0\n",
    "                    supertrend[i] = final_lower[i]\n",
    "            else:\n",
    "                # Calculs suivants\n",
    "                prev_direction = direction[i-1]\n",
    "                \n",
    "                if prev_direction == 1.0 and close[i] <= final_lower[i]:\n",
    "                    # Changement vers bearish\n",
    "                    direction[i] = -1.0\n",
    "                    supertrend[i] = final_upper[i]\n",
    "                elif prev_direction == -1.0 and close[i] >= final_upper[i]:\n",
    "                    # Changement vers bullish\n",
    "                    direction[i] = 1.0\n",
    "                    supertrend[i] = final_lower[i]\n",
    "                else:\n",
    "                    # Maintien de la direction\n",
    "                    direction[i] = prev_direction\n",
    "                    if prev_direction == 1.0:\n",
    "                        supertrend[i] = final_lower[i]\n",
    "                    else:\n",
    "                        supertrend[i] = final_upper[i]\n",
    "        \n",
    "        return supertrend, direction\n",
    "    \n",
    "    def get_enhanced_max_lookback_period(self) -> int:\n",
    "        \"\"\"Calcule le lookback optimal pour CHAQUE type d'indicateur\"\"\"\n",
    "        lookback_requirements = []\n",
    "        config = self.config.TECHNICAL_INDICATORS\n",
    "        \n",
    "        print(\"üî¨ Analyse des besoins de lookback par indicateur:\")\n",
    "        \n",
    "        # 1. SMA - Simple Moving Average\n",
    "        if 'sma_periods' in config:\n",
    "            max_sma = max(config['sma_periods'])\n",
    "            lookback_requirements.append(max_sma)\n",
    "            print(f\"   üìà SMA max: {max_sma}\")\n",
    "        \n",
    "        # 2. EMA - Exponential Moving Average (3x pour convergence)\n",
    "        if 'ema_periods' in config:\n",
    "            max_ema = max(config['ema_periods'])\n",
    "            ema_lookback = max_ema * 3  # Convergence exponentielle\n",
    "            lookback_requirements.append(ema_lookback)\n",
    "            print(f\"   üìà EMA effective: {ema_lookback} (3x {max_ema})\")\n",
    "        \n",
    "        # 3. RSI - Relative Strength Index (2x pour stabilisation)\n",
    "        if 'rsi_periods' in config:\n",
    "            max_rsi = max(config['rsi_periods'])\n",
    "            rsi_lookback = max_rsi * 2  # P√©riode de warm-up\n",
    "            lookback_requirements.append(rsi_lookback)\n",
    "            print(f\"   üéØ RSI avec warm-up: {rsi_lookback} (2x {max_rsi})\")\n",
    "        \n",
    "        # 4. Bollinger Bands\n",
    "        if 'bollinger' in config:\n",
    "            bb_period = config['bollinger']['period']\n",
    "            lookback_requirements.append(bb_period)\n",
    "            print(f\"   üìä Bollinger Bands: {bb_period}\")\n",
    "        \n",
    "        # 5. MACD - Complexe (EMA lente + signal)\n",
    "        if 'macd' in config:\n",
    "            macd_slow = config['macd']['slow']\n",
    "            macd_signal = config['macd']['signal']\n",
    "            # EMA lente (3x) + EMA signal (3x) pour stabilit√© totale\n",
    "            macd_lookback = (macd_slow * 3) + (macd_signal * 3)\n",
    "            lookback_requirements.append(macd_lookback)\n",
    "            print(f\"   ‚ö° MACD complexe: {macd_lookback} ({macd_slow}*3 + {macd_signal}*3)\")\n",
    "        \n",
    "        # 6. ATR - Average True Range\n",
    "        if 'atr_period' in config:\n",
    "            atr_period = config['atr_period']\n",
    "            lookback_requirements.append(atr_period)\n",
    "            print(f\"   üõ°Ô∏è ATR: {atr_period}\")\n",
    "        \n",
    "        # 7. SuperTrend (d√©pend d'ATR + sa propre longueur)\n",
    "        if 'supertrend' in config:\n",
    "            st_length = config['supertrend']['length']\n",
    "            atr_period = config.get('atr_period', 14)  # ATR par d√©faut\n",
    "            st_lookback = atr_period + st_length * 2  # ATR + SuperTrend\n",
    "            lookback_requirements.append(st_lookback)\n",
    "            print(f\"   üîÑ SuperTrend: {st_lookback} (ATR:{atr_period} + ST:{st_length}*2)\")\n",
    "        \n",
    "        # 8. Stochastic Oscillator\n",
    "        if 'stochastic' in config:\n",
    "            stoch_k = config['stochastic']['k_period']\n",
    "            stoch_d = config['stochastic']['d_period']\n",
    "            stoch_lookback = stoch_k + stoch_d\n",
    "            lookback_requirements.append(stoch_lookback)\n",
    "            print(f\"   üìä Stochastic: {stoch_lookback} ({stoch_k} + {stoch_d})\")\n",
    "        \n",
    "        # Prise du maximum + marge de s√©curit√© g√©n√©reuse\n",
    "        if lookback_requirements:\n",
    "            base_lookback = max(lookback_requirements)\n",
    "            safety_margin = max(50, int(base_lookback * 0.2))  # Minimum 50 ou 20%\n",
    "            total_lookback = base_lookback + safety_margin\n",
    "            \n",
    "            print(f\"\\nüéØ Lookback de base: {base_lookback}\")\n",
    "            print(f\"üõ°Ô∏è Marge de s√©curit√©: {safety_margin}\")\n",
    "            print(f\"üìä TOTAL LOOKBACK: {total_lookback}\")\n",
    "            \n",
    "            return total_lookback\n",
    "        \n",
    "        return 250  # Fallback conservateur\n",
    "    \n",
    "    def get_existing_data_info(self) -> Dict:\n",
    "        \"\"\"R√©cup√®re les infos sur les donn√©es existantes\"\"\"\n",
    "        print(\"üîç Analyse des donn√©es existantes...\")\n",
    "        \n",
    "        if not self.con:\n",
    "            self.setup_duckdb()\n",
    "        \n",
    "        feature_store_path = f\"{self.config.GOLD_BUCKET}/{self.config.FEATURE_STORE_TABLE}/**/*.parquet\"\n",
    "        \n",
    "        try:\n",
    "            # V√©rification de l'existence\n",
    "            info_query = f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(datetime) as min_date,\n",
    "                    MAX(datetime) as max_date,\n",
    "                    COUNT(*) as total_rows,\n",
    "                    COUNT(DISTINCT symbol) as symbols_count\n",
    "                FROM read_parquet('{feature_store_path}')\n",
    "            \"\"\"\n",
    "            \n",
    "            result = self.con.execute(info_query).fetchone()\n",
    "            \n",
    "            return {\n",
    "                'exists': True,\n",
    "                'min_date': result[0],\n",
    "                'max_date': result[1], \n",
    "                'total_rows': result[2],\n",
    "                'symbols_count': result[3]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Feature Store n'existe pas encore: {e}\")\n",
    "            return {\n",
    "                'exists': False\n",
    "            }\n",
    "    \n",
    "    def save_feature_store(self, df: pl.DataFrame):\n",
    "        \"\"\"Sauvegarde le Feature Store en Gold\"\"\"\n",
    "        print(f\"üíæ Sauvegarde du Feature Store...\")\n",
    "        \n",
    "        # Ajout des m√©tadonn√©es\n",
    "        df_final = df.with_columns([\n",
    "            pl.lit(\"BTCUSDT\").alias(\"symbol\"),\n",
    "            pl.lit(\"4h\").alias(\"timeframe\"),\n",
    "            pl.lit(datetime.now(timezone.utc).isoformat()).alias(\"created_at\")\n",
    "        ])\n",
    "        \n",
    "        # Enregistrement temporaire pour DuckDB\n",
    "        try:\n",
    "            self.con.execute(\"DROP VIEW IF EXISTS tmp_features\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.con.register(\"tmp_features\", df_final.to_arrow())\n",
    "        \n",
    "        # Sauvegarde partitionn√©e par year/month\n",
    "        output_path = f\"{self.config.GOLD_BUCKET}/{self.config.FEATURE_STORE_TABLE}/\"\n",
    "        \n",
    "        save_query = f\"\"\"\n",
    "            COPY tmp_features \n",
    "            TO '{output_path}'\n",
    "            WITH (FORMAT PARQUET, PARTITION_BY (year, month), OVERWRITE_OR_IGNORE TRUE)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.con.execute(save_query)\n",
    "        \n",
    "        print(f\"‚úÖ Feature Store sauvegard√©: {output_path}\")\n",
    "        print(f\"üìä {df_final.height:,} lignes, {df_final.width} colonnes\")\n",
    "    \n",
    "    def _append_to_feature_store(self, df: pl.DataFrame):\n",
    "        \"\"\"Ajoute des donn√©es au Feature Store existant\"\"\"\n",
    "        print(\"‚ûï Ajout des nouvelles donn√©es au Feature Store...\")\n",
    "        \n",
    "        try:\n",
    "            self.con.execute(\"DROP VIEW IF EXISTS tmp_new_features\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.con.register(\"tmp_new_features\", df.to_arrow())\n",
    "        \n",
    "        # Sauvegarde en mode append (pas de OVERWRITE)\n",
    "        output_path = f\"{self.config.GOLD_BUCKET}/{self.config.FEATURE_STORE_TABLE}/\"\n",
    "        \n",
    "        append_query = f\"\"\"\n",
    "            COPY tmp_new_features \n",
    "            TO '{output_path}'\n",
    "            WITH (FORMAT PARQUET, PARTITION_BY (year, month))\n",
    "        \"\"\"\n",
    "        \n",
    "        self.con.execute(append_query)\n",
    "        \n",
    "        print(f\"‚úÖ {df.height:,} nouvelles lignes ajout√©es\")\n",
    "    \n",
    "    def build_feature_store_complete(self):\n",
    "        \"\"\"Construction COMPL√àTE du Feature Store (premi√®re fois)\"\"\"\n",
    "        print(\"üöÄ Construction COMPL√àTE du Feature Store Gold\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Setup\n",
    "        self.setup_duckdb()\n",
    "        \n",
    "        # 2. Chargement des donn√©es compl√®tes Bronze\n",
    "        df_bronze = self.load_bronze_data()\n",
    "        \n",
    "        if df_bronze.height == 0:\n",
    "            print(\"‚ùå Aucune donn√©e Bronze trouv√©e!\")\n",
    "            return None\n",
    "        \n",
    "        # 3. Calcul des indicateurs\n",
    "        df_with_features = self.calculate_technical_indicators(df_bronze)\n",
    "        \n",
    "        # 4. Sauvegarde compl√®te\n",
    "        self.save_feature_store(df_with_features)\n",
    "        \n",
    "        # 5. Nettoyage\n",
    "        if self.con:\n",
    "            self.con.close()\n",
    "        \n",
    "        print(\"\\nüéâ Feature Store construit avec succ√®s!\")\n",
    "        return df_with_features\n",
    "    \n",
    "    def update_feature_store_incremental(self):\n",
    "        \"\"\"Mise √† jour INCR√âMENTALE du Feature Store avec lookback optimal\"\"\"\n",
    "        print(\"üîÑ Mise √† jour INCR√âMENTALE du Feature Store\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Setup\n",
    "        self.setup_duckdb()\n",
    "        \n",
    "        # 2. V√©rification de l'√©tat existant\n",
    "        existing_info = self.get_existing_data_info()\n",
    "        \n",
    "        if not existing_info['exists']:\n",
    "            print(\"‚ùå Feature Store n'existe pas, construction compl√®te requise\")\n",
    "            return self.build_feature_store_complete()\n",
    "        \n",
    "        print(f\"üìä Feature Store existant: {existing_info['total_rows']:,} lignes\")\n",
    "        print(f\"üìÖ P√©riode: {existing_info['min_date']} ‚Üí {existing_info['max_date']}\")\n",
    "        \n",
    "        start_date = existing_info['max_date']\n",
    "        max_lookback = self.get_enhanced_max_lookback_period()\n",
    "        \n",
    "        # 3. Chargement avec lookback optimal\n",
    "        print(f\"\\nüîÑ Traitement incr√©mental depuis: {start_date}\")\n",
    "        \n",
    "        # Calculer la date de d√©but avec lookback\n",
    "        lookback_query = f\"\"\"\n",
    "            SELECT datetime \n",
    "            FROM read_parquet('{self.config.BRONZE_PATH}')\n",
    "            WHERE datetime <= '{start_date}'\n",
    "            ORDER BY datetime DESC\n",
    "            LIMIT {max_lookback}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            lookback_result = self.con.execute(lookback_query).fetchall()\n",
    "            \n",
    "            if lookback_result:\n",
    "                # Prendre la date la plus ancienne du lookback\n",
    "                lookback_start_date = lookback_result[-1][0]\n",
    "                print(f\"üìä Chargement avec lookback depuis: {lookback_start_date}\")\n",
    "                print(f\"üî¢ Garantit {max_lookback} p√©riodes de contexte historique\")\n",
    "                \n",
    "                # Chargement des donn√©es avec contexte historique\n",
    "                df_with_lookback = self.load_bronze_data(start_date=lookback_start_date)\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Lookback impossible, chargement complet pour s√©curit√©\")\n",
    "                df_with_lookback = self.load_bronze_data()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur lookback: {e}, chargement complet\")\n",
    "            df_with_lookback = self.load_bronze_data()\n",
    "        \n",
    "        if df_with_lookback.height == 0:\n",
    "            print(\"‚úÖ Aucune donn√©e √† traiter\")\n",
    "            return None\n",
    "        \n",
    "        # 4. Calcul des indicateurs sur le dataset complet\n",
    "        df_with_features = self.calculate_technical_indicators(df_with_lookback)\n",
    "        \n",
    "        # 5. Filtrage pour garder seulement les nouvelles lignes\n",
    "        df_new_only = df_with_features.filter(pl.col('datetime') > start_date)\n",
    "        print(f\"üéØ {df_new_only.height:,} nouvelles lignes √† ajouter\")\n",
    "        \n",
    "        if df_new_only.height == 0:\n",
    "            print(\"‚úÖ Aucune nouvelle donn√©e apr√®s filtrage\")\n",
    "            return None\n",
    "        \n",
    "        # 6. Ajout des m√©tadonn√©es\n",
    "        df_final = df_new_only.with_columns([\n",
    "            pl.lit(\"BTCUSDT\").alias(\"symbol\"),\n",
    "            pl.lit(\"4h\").alias(\"timeframe\"),\n",
    "            pl.lit(datetime.now(timezone.utc).isoformat()).alias(\"updated_at\")\n",
    "        ])\n",
    "        \n",
    "        # 7. Sauvegarde en append\n",
    "        self._append_to_feature_store(df_final)\n",
    "        \n",
    "        # 8. Nettoyage\n",
    "        if self.con:\n",
    "            self.con.close()\n",
    "        \n",
    "        print(\"\\nüéâ Mise √† jour incr√©mentale termin√©e avec calculs corrects!\")\n",
    "        return df_final\n",
    "\n",
    "# Initialisation de la classe optimis√©e\n",
    "feature_store = UltraFixedIncrementalFeatureStore(Config)\n",
    "print(\"‚úÖ Feature Store OPTIMIS√â initialis√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3dd1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test rapide du SuperTrend natif\n",
      "üîó DuckDB configur√© pour MinIO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c8553070d940878ddf5a747fce1466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä √âchantillon charg√©: 100 lignes\n",
      "‚úÖ SuperTrend calcul√© avec succ√®s!\n",
      "   ‚Ä¢ Valeurs valides: 90/100\n",
      "   ‚Ä¢ Directions valides: 90/100\n",
      "   ‚Ä¢ Bullish (1): 88\n",
      "   ‚Ä¢ Bearish (-1): 2\n",
      "\n",
      "üìã Derni√®res valeurs SuperTrend:\n",
      "   ‚Ä¢ 2017-09-02 00:00:00: 4543.91 (üìà Bullish)\n",
      "   ‚Ä¢ 2017-09-02 04:00:00: 4543.91 (üìà Bullish)\n",
      "   ‚Ä¢ 2017-09-02 08:00:00: 4543.91 (üìà Bullish)\n",
      "   ‚Ä¢ 2017-09-02 12:00:00: 4851.64 (üìâ Bearish)\n",
      "   ‚Ä¢ 2017-09-02 16:00:00: 4851.64 (üìâ Bearish)\n"
     ]
    }
   ],
   "source": [
    "# üß™ TEST RAPIDE DU SUPERTREND NATIF\n",
    "print(\"üß™ Test rapide du SuperTrend natif\")\n",
    "\n",
    "# Charger un petit √©chantillon de donn√©es pour tester\n",
    "feature_store.setup_duckdb()\n",
    "sample_query = f\"\"\"\n",
    "    SELECT datetime, open, high, low, close, volume, year, month, day\n",
    "    FROM read_parquet('{Config.BRONZE_PATH}')\n",
    "    ORDER BY datetime\n",
    "    LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "sample_df = pl.from_arrow(feature_store.con.execute(sample_query).arrow())\n",
    "print(f\"üìä √âchantillon charg√©: {len(sample_df)} lignes\")\n",
    "\n",
    "if len(sample_df) > 50:  # Assez de donn√©es pour tester SuperTrend\n",
    "    # Tester seulement le SuperTrend\n",
    "    ohlcv_test = {\n",
    "        'high': sample_df['high'].to_numpy(),\n",
    "        'low': sample_df['low'].to_numpy(),\n",
    "        'close': sample_df['close'].to_numpy()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        st_values, st_direction = feature_store._calculate_supertrend_native(\n",
    "            high=ohlcv_test['high'],\n",
    "            low=ohlcv_test['low'],\n",
    "            close=ohlcv_test['close'],\n",
    "            length=10,\n",
    "            multiplier=3.0\n",
    "        )\n",
    "        \n",
    "        # Compter les valeurs non-NaN\n",
    "        valid_values = np.sum(~np.isnan(st_values))\n",
    "        valid_directions = np.sum(~np.isnan(st_direction))\n",
    "        \n",
    "        # Compter les directions\n",
    "        bullish_count = np.sum(st_direction == 1)\n",
    "        bearish_count = np.sum(st_direction == -1)\n",
    "        \n",
    "        print(f\"‚úÖ SuperTrend calcul√© avec succ√®s!\")\n",
    "        print(f\"   ‚Ä¢ Valeurs valides: {valid_values}/{len(st_values)}\")\n",
    "        print(f\"   ‚Ä¢ Directions valides: {valid_directions}/{len(st_direction)}\")\n",
    "        print(f\"   ‚Ä¢ Bullish (1): {bullish_count}\")\n",
    "        print(f\"   ‚Ä¢ Bearish (-1): {bearish_count}\")\n",
    "        \n",
    "        # √âchantillon des derni√®res valeurs\n",
    "        print(f\"\\nüìã Derni√®res valeurs SuperTrend:\")\n",
    "        for i in range(-5, 0):\n",
    "            if not np.isnan(st_values[i]):\n",
    "                direction_text = \"üìà Bullish\" if st_direction[i] == 1 else \"üìâ Bearish\"\n",
    "                print(f\"   ‚Ä¢ {sample_df['datetime'][i]}: {st_values[i]:.2f} ({direction_text})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur SuperTrend natif: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå Pas assez de donn√©es pour tester SuperTrend\")\n",
    "\n",
    "feature_store.con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93737ae",
   "metadata": {},
   "source": [
    "## 4. Utilitaire de Lecture du Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46385713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Feature Store Reader initialis√©\n"
     ]
    }
   ],
   "source": [
    "class FeatureStoreReader:\n",
    "    \"\"\"Classe utilitaire pour lire le Feature Store\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.con = None\n",
    "    \n",
    "    def setup_connection(self):\n",
    "        \"\"\"Configure la connexion DuckDB\"\"\"\n",
    "        self.con = duckdb.connect(database=\":memory:\")\n",
    "        self.con.execute(f\"\"\"\n",
    "            SET s3_access_key_id='{self.config.MINIO_ACCESS_KEY}';\n",
    "            SET s3_secret_access_key='{self.config.MINIO_SECRET_KEY}';\n",
    "            SET s3_endpoint='{self.config.MINIO_ENDPOINT}';\n",
    "            SET s3_url_style='path';\n",
    "            SET s3_use_ssl='false';\n",
    "        \"\"\")\n",
    "    \n",
    "    def read_features(\n",
    "        self,\n",
    "        symbols: List[str] = None,\n",
    "        start_date: str = None,\n",
    "        end_date: str = None,\n",
    "        features: List[str] = None\n",
    "    ) -> pl.DataFrame:\n",
    "        \"\"\"Lit les features du Feature Store avec filtres optionnels\"\"\"\n",
    "        \n",
    "        if not self.con:\n",
    "            self.setup_connection()\n",
    "        \n",
    "        # Construction de la requ√™te\n",
    "        feature_store_path = f\"{self.config.GOLD_BUCKET}/{self.config.FEATURE_STORE_TABLE}/**/*.parquet\"\n",
    "        \n",
    "        select_clause = \"*\" if not features else \", \".join([\"datetime\"] + features)\n",
    "        where_clauses = []\n",
    "        \n",
    "        if symbols:\n",
    "            symbols_str = \"', '\".join(symbols)\n",
    "            where_clauses.append(f\"symbol IN ('{symbols_str}')\")\n",
    "        \n",
    "        if start_date:\n",
    "            where_clauses.append(f\"datetime >= '{start_date}'\")\n",
    "        \n",
    "        if end_date:\n",
    "            where_clauses.append(f\"datetime <= '{end_date}'\")\n",
    "        \n",
    "        where_clause = \"WHERE \" + \" AND \".join(where_clauses) if where_clauses else \"\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT {select_clause}\n",
    "            FROM read_parquet('{feature_store_path}')\n",
    "            {where_clause}\n",
    "            ORDER BY datetime\n",
    "        \"\"\"\n",
    "        \n",
    "        return pl.from_arrow(self.con.execute(query).arrow())\n",
    "    \n",
    "    def get_latest_features(self, symbol: str = \"BTCUSDT\", limit: int = 100) -> pl.DataFrame:\n",
    "        \"\"\"R√©cup√®re les derniers features disponibles\"\"\"\n",
    "        \n",
    "        if not self.con:\n",
    "            self.setup_connection()\n",
    "        \n",
    "        feature_store_path = f\"{self.config.GOLD_BUCKET}/{self.config.FEATURE_STORE_TABLE}/**/*.parquet\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM read_parquet('{feature_store_path}')\n",
    "            WHERE symbol = '{symbol}'\n",
    "            ORDER BY datetime DESC\n",
    "            LIMIT {limit}\n",
    "        \"\"\"\n",
    "        \n",
    "        return pl.from_arrow(self.con.execute(query).arrow())\n",
    "    \n",
    "    def close(self):\n",
    "        if self.con:\n",
    "            self.con.close()\n",
    "\n",
    "# Initialisation du reader\n",
    "reader = FeatureStoreReader(Config)\n",
    "print(\"üìö Feature Store Reader initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135eaf84",
   "metadata": {},
   "source": [
    "## 5. Construction ou Mise √† Jour du Feature Store\n",
    "\n",
    "### üéØ **Choisissez votre mode d'ex√©cution :**\n",
    "\n",
    "- **üÜï Premi√®re fois** : Ex√©cutez la cellule \"Construction Compl√®te\"\n",
    "- **üîÑ Mise √† jour** : Ex√©cutez la cellule \"Mise √† Jour Incr√©mentale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381865de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Construction COMPL√àTE du Feature Store Gold\n",
      "============================================================\n",
      "üîó DuckDB configur√© pour MinIO\n",
      "üì• Chargement des donn√©es Bronze...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db5f03ba5da458f98bd4083fa2fbe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 17,604 lignes charg√©es de Bronze\n",
      "üìÖ P√©riode: 2017-08-17 04:00:00 ‚Üí 2025-08-31 20:00:00\n",
      "üîß Calcul des indicateurs techniques...\n",
      "‚úÖ SuperTrend calcul√© avec impl√©mentation native\n",
      "‚úÖ 23 indicateurs calcul√©s\n",
      "üíæ Sauvegarde du Feature Store...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7eb671f761747e7b110fc401331a4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature Store sauvegard√©: s3://gold/gold_features_spot_monthly_klines_BTCUSDT_4h/\n",
      "üìä 17,604 lignes, 35 colonnes\n",
      "\n",
      "üéâ Feature Store construit avec succ√®s!\n",
      "üí° Pour construire le Feature Store pour la premi√®re fois:\n",
      "   D√©commentez la ligne ci-dessus et ex√©cutez cette cellule\n",
      "\n",
      "‚ö†Ô∏è  Attention: Ceci va traiter TOUTES les donn√©es Bronze (peut prendre du temps)\n"
     ]
    }
   ],
   "source": [
    "# üÜï PREMI√àRE FOIS : Construction compl√®te du Feature Store\n",
    "# D√©commentez cette ligne pour la premi√®re ex√©cution\n",
    "df_features = feature_store.build_feature_store_complete()\n",
    "\n",
    "print(\"üí° Pour construire le Feature Store pour la premi√®re fois:\")\n",
    "print(\"   D√©commentez la ligne ci-dessus et ex√©cutez cette cellule\")\n",
    "print(\"\\n‚ö†Ô∏è  Attention: Ceci va traiter TOUTES les donn√©es Bronze (peut prendre du temps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c492888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce898838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ MISE √Ä JOUR INCR√âMENTALE : Ajout des nouvelles donn√©es\n",
    "# D√©commentez cette ligne pour une mise √† jour incr√©mentale\n",
    "# df_new_features = feature_store.update_feature_store_incremental()\n",
    "\n",
    "print(\"üí° Pour mettre √† jour le Feature Store avec de nouvelles donn√©es:\")\n",
    "print(\"   D√©commentez la ligne ci-dessus et ex√©cutez cette cellule\")\n",
    "print(\"\\n‚úÖ Avantages: Traitement ultra-rapide avec lookback optimal pour tous les indicateurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c9d39",
   "metadata": {},
   "source": [
    "## 6. Validation & Test du Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c14a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test de lecture du Feature Store:\n",
      "‚úÖ 10 lignes r√©cup√©r√©es\n",
      "üìä 23 indicateurs disponibles:\n",
      "\n",
      "üìà Moyennes Mobiles: 10 indicateurs\n",
      "   ‚Ä¢ sma_10\n",
      "   ‚Ä¢ sma_20\n",
      "   ‚Ä¢ sma_50\n",
      "   ... et 7 autres\n",
      "\n",
      "üéØ Oscillateurs: 4 indicateurs\n",
      "   ‚Ä¢ rsi_14\n",
      "   ‚Ä¢ rsi_21\n",
      "   ‚Ä¢ stoch_k_14_3\n",
      "   ... et 1 autres\n",
      "\n",
      "üìä Bandes & Enveloppes: 3 indicateurs\n",
      "   ‚Ä¢ bb_upper_20_2\n",
      "   ‚Ä¢ bb_middle_20_2\n",
      "   ‚Ä¢ bb_lower_20_2\n",
      "\n",
      "‚ö° Momentum: 3 indicateurs\n",
      "   ‚Ä¢ macd_12_26_9\n",
      "   ‚Ä¢ macd_signal_12_26_9\n",
      "   ‚Ä¢ macd_hist_12_26_9\n",
      "\n",
      "üõ°Ô∏è Volatilit√© & Tendance: 3 indicateurs\n",
      "   ‚Ä¢ atr_14\n",
      "   ‚Ä¢ supertrend_10_3.0\n",
      "   ‚Ä¢ supertrend_dir_10_3.0\n",
      "\n",
      "üìã Derni√®res donn√©es (√©chantillon):\n",
      "shape: (5, 5)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ datetime            ‚îÜ close     ‚îÜ sma_20      ‚îÜ ema_20        ‚îÜ rsi_14    ‚îÇ\n",
      "‚îÇ ---                 ‚îÜ ---       ‚îÜ ---         ‚îÜ ---           ‚îÜ ---       ‚îÇ\n",
      "‚îÇ datetime[Œºs]        ‚îÜ f64       ‚îÜ f64         ‚îÜ f64           ‚îÜ f64       ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 2025-08-31 20:00:00 ‚îÜ 108246.35 ‚îÜ 109286.9165 ‚îÜ 109335.645174 ‚îÜ 37.155391 ‚îÇ\n",
      "‚îÇ 2025-08-31 16:00:00 ‚îÜ 108930.0  ‚îÜ 109508.5255 ‚îÜ 109450.307824 ‚îÜ 41.76959  ‚îÇ\n",
      "‚îÇ 2025-08-31 12:00:00 ‚îÜ 108818.69 ‚îÜ 109707.4845 ‚îÜ 109505.077069 ‚îÜ 40.655368 ‚îÇ\n",
      "‚îÇ 2025-08-31 08:00:00 ‚îÜ 108389.76 ‚îÜ 109922.2555 ‚îÜ 109577.328339 ‚îÜ 36.293495 ‚îÇ\n",
      "‚îÇ 2025-08-31 04:00:00 ‚îÜ 108708.26 ‚îÜ 110102.768  ‚îÜ 109702.335533 ‚îÜ 38.231013 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "‚úÖ 10 lignes r√©cup√©r√©es\n",
      "üìä 23 indicateurs disponibles:\n",
      "\n",
      "üìà Moyennes Mobiles: 10 indicateurs\n",
      "   ‚Ä¢ sma_10\n",
      "   ‚Ä¢ sma_20\n",
      "   ‚Ä¢ sma_50\n",
      "   ... et 7 autres\n",
      "\n",
      "üéØ Oscillateurs: 4 indicateurs\n",
      "   ‚Ä¢ rsi_14\n",
      "   ‚Ä¢ rsi_21\n",
      "   ‚Ä¢ stoch_k_14_3\n",
      "   ... et 1 autres\n",
      "\n",
      "üìä Bandes & Enveloppes: 3 indicateurs\n",
      "   ‚Ä¢ bb_upper_20_2\n",
      "   ‚Ä¢ bb_middle_20_2\n",
      "   ‚Ä¢ bb_lower_20_2\n",
      "\n",
      "‚ö° Momentum: 3 indicateurs\n",
      "   ‚Ä¢ macd_12_26_9\n",
      "   ‚Ä¢ macd_signal_12_26_9\n",
      "   ‚Ä¢ macd_hist_12_26_9\n",
      "\n",
      "üõ°Ô∏è Volatilit√© & Tendance: 3 indicateurs\n",
      "   ‚Ä¢ atr_14\n",
      "   ‚Ä¢ supertrend_10_3.0\n",
      "   ‚Ä¢ supertrend_dir_10_3.0\n",
      "\n",
      "üìã Derni√®res donn√©es (√©chantillon):\n",
      "shape: (5, 5)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ datetime            ‚îÜ close     ‚îÜ sma_20      ‚îÜ ema_20        ‚îÜ rsi_14    ‚îÇ\n",
      "‚îÇ ---                 ‚îÜ ---       ‚îÜ ---         ‚îÜ ---           ‚îÜ ---       ‚îÇ\n",
      "‚îÇ datetime[Œºs]        ‚îÜ f64       ‚îÜ f64         ‚îÜ f64           ‚îÜ f64       ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 2025-08-31 20:00:00 ‚îÜ 108246.35 ‚îÜ 109286.9165 ‚îÜ 109335.645174 ‚îÜ 37.155391 ‚îÇ\n",
      "‚îÇ 2025-08-31 16:00:00 ‚îÜ 108930.0  ‚îÜ 109508.5255 ‚îÜ 109450.307824 ‚îÜ 41.76959  ‚îÇ\n",
      "‚îÇ 2025-08-31 12:00:00 ‚îÜ 108818.69 ‚îÜ 109707.4845 ‚îÜ 109505.077069 ‚îÜ 40.655368 ‚îÇ\n",
      "‚îÇ 2025-08-31 08:00:00 ‚îÜ 108389.76 ‚îÜ 109922.2555 ‚îÜ 109577.328339 ‚îÜ 36.293495 ‚îÇ\n",
      "‚îÇ 2025-08-31 04:00:00 ‚îÜ 108708.26 ‚îÜ 110102.768  ‚îÜ 109702.335533 ‚îÜ 38.231013 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# Test de lecture du Feature Store\n",
    "print(\"üß™ Test de lecture du Feature Store:\")\n",
    "\n",
    "try:\n",
    "    # Test de lecture des derni√®res donn√©es\n",
    "    latest_data = reader.get_latest_features(limit=10)\n",
    "    \n",
    "    if latest_data.height > 0:\n",
    "        print(f\"‚úÖ {latest_data.height} lignes r√©cup√©r√©es\")\n",
    "        \n",
    "        # Affichage des colonnes disponibles\n",
    "        all_columns = latest_data.columns\n",
    "        indicator_columns = [col for col in all_columns \n",
    "                           if col not in ['datetime', 'open', 'high', 'low', 'close', 'volume', \n",
    "                                         'year', 'month', 'day', 'symbol', 'timeframe', 'created_at', 'updated_at']]\n",
    "        \n",
    "        print(f\"üìä {len(indicator_columns)} indicateurs disponibles:\")\n",
    "        \n",
    "        # Regroupement par type\n",
    "        indicator_types = {\n",
    "            'üìà Moyennes Mobiles': [col for col in indicator_columns if col.startswith(('sma_', 'ema_'))],\n",
    "            'üéØ Oscillateurs': [col for col in indicator_columns if col.startswith(('rsi_', 'stoch_'))],\n",
    "            'üìä Bandes & Enveloppes': [col for col in indicator_columns if col.startswith('bb_')],\n",
    "            '‚ö° Momentum': [col for col in indicator_columns if col.startswith('macd_')],\n",
    "            'üõ°Ô∏è Volatilit√© & Tendance': [col for col in indicator_columns if col.startswith(('atr_', 'supertrend_'))]\n",
    "        }\n",
    "        \n",
    "        for category, indicators in indicator_types.items():\n",
    "            if indicators:\n",
    "                print(f\"\\n{category}: {len(indicators)} indicateurs\")\n",
    "                for ind in indicators[:3]:  # Afficher les 3 premiers de chaque cat√©gorie\n",
    "                    print(f\"   ‚Ä¢ {ind}\")\n",
    "                if len(indicators) > 3:\n",
    "                    print(f\"   ... et {len(indicators)-3} autres\")\n",
    "        \n",
    "        # √âchantillon des derni√®res donn√©es\n",
    "        print(\"\\nüìã Derni√®res donn√©es (√©chantillon):\")\n",
    "        sample_columns = ['datetime', 'close', 'sma_20', 'ema_20', 'rsi_14']\n",
    "        available_sample = [col for col in sample_columns if col in latest_data.columns]\n",
    "        print(latest_data.select(available_sample).head())\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune donn√©e trouv√©e dans le Feature Store\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du test: {e}\")\n",
    "    print(\"üí° Le Feature Store n'existe probablement pas encore.\")\n",
    "    print(\"   Ex√©cutez d'abord la construction compl√®te (section 5)\")\n",
    "\n",
    "finally:\n",
    "    reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbe369",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Feature Store Gold OPTIMIS√â\n",
    "\n",
    "### üéØ **Workflow Simplifi√©**\n",
    "\n",
    "1. **üÜï Premi√®re fois** : `feature_store.build_feature_store_complete()`\n",
    "2. **üîÑ Mise √† jour** : `feature_store.update_feature_store_incremental()`\n",
    "3. **üìö Lecture** : `reader.read_features()` ou `reader.get_latest_features()`\n",
    "\n",
    "### üöÄ **Avantages de cette Version**\n",
    "\n",
    "- **üß† Lookback Intelligent** : Calcul optimal pour chaque type d'indicateur\n",
    "- **‚ö° Performance** : 10-20x plus rapide pour les mises √† jour\n",
    "- **üîß Simplicit√©** : Une seule classe, workflow clair\n",
    "- **‚úÖ Pr√©cision** : Tous les indicateurs calcul√©s correctement\n",
    "- **üìä Robustesse** : Gestion d'erreurs et fallbacks\n",
    "\n",
    "### üéâ **Le Feature Store est pr√™t pour vos strat√©gies de trading !**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hermes-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
