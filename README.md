# Hermes Data Lab

Ce document d√©crit l'architecture du Data Lab Hermes, une plateforme con√ßue pour l'ingestion, la transformation et l'analyse de donn√©es financi√®res en vue de d√©velopper et backtester des strat√©gies de trading.

üèõÔ∏è Architecture G√©n√©rale : Mod√®le Medallion

L'architecture repose sur le mod√®le Medallion en trois couches (Bronze, Argent, Or). Ce mod√®le garantit une s√©paration claire des responsabilit√©s, une tra√ßabilit√© des donn√©es et une mont√©e en qualit√© progressive, de la donn√©e brute √† la donn√©e pr√™te √† l'emploi.
Plaintext

          +-------------------------+
          |     Source : NFS        |
          |  Fichiers bruts (.zip)  |
          | (Donn√©es d'API, etc.)   |
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |      ü•â Couche Bronze     |
          | - Tables brutes, immuables|
          | - Partitionn√©es par date  |
          | - Format : Parquet        |
          | - Stockage : MinIO        |
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |      ü•à Couche Argent     |
          | - Donn√©es nettoy√©es, valid√©es|
          | - Types, dates et sch√©mas standardis√©s |
          | - Contr√¥les qualit√©       |
          | - Stockage : MinIO        |
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |       ü•á Couche Or        |
          | - Datamarts sp√©cialis√©s   |
          | - Donn√©es enrichies, agr√©g√©es|
          | - Indicateurs de trading  |
          | - Stockage : MinIO        |
          +-------------------------+

üõ†Ô∏è √âcosyst√®me Technologique

Notre architecture s'appuie sur des outils modernes et performants, choisis pour leur efficacit√© dans le traitement de donn√©es volumineuses.
Outil	R√¥le dans l'architecture
MinIO (S3)	Data Lake central pour le stockage des couches Bronze, Argent et Or.
DuckDB	Moteur d'interrogation SQL rapide pour lire/√©crire sur MinIO, effectuer des jointures et des agr√©gations.
Polars	Moteur de transformation ultra-rapide pour le nettoyage, le calcul d'indicateurs et les manipulations complexes de DataFrames.
Jupyter Notebook	Interface d'analyse et d'exploration pour le d√©veloppement des strat√©gies, la visualisation et le backtesting.

üåä Flux de Donn√©es (Data Flow)

Le parcours de la donn√©e suit un processus clair √† travers les trois couches.

√âtape 1 : Ingestion (Source ‚Üí Bronze)

L'objectif de cette √©tape est de cr√©er une copie brute, fiable et partitionn√©e des donn√©es sources.

    Les fichiers .zip contenant les donn√©es brutes sont r√©cup√©r√©s depuis le montage NFS.

    Un script lit chaque archive, ajoute des colonnes de date (year, month, day) pour le partitionnement.

    Les donn√©es sont √©crites sur MinIO au format Parquet, partitionn√©es par date. Polars et DuckDB sont utilis√©s pour leur efficacit√© dans ce processus.

√âtape 2 : Structuration et Nettoyage (Bronze ‚Üí Argent)

Ici, nous transformons les donn√©es brutes en une source de v√©rit√© propre et fiable.

    Les tables de la couche Bronze sont lues depuis MinIO.

    Des transformations structurelles sont appliqu√©es avec Polars :

        Conversion des timestamps en dates lisibles et fuseaux horaires coh√©rents.

        Correction et unification des types de donn√©es (ex: string ‚Üí float).

        Application de contr√¥les qualit√© pour d√©tecter les anomalies (valeurs manquantes, outliers).

    Les tables nettoy√©es et structur√©es sont √©crites dans la couche Argent sur MinIO.

√âtape 3 : Enrichissement M√©tier (Argent ‚Üí Or)

Cette couche cr√©e des datamarts sp√©cialis√©s, pr√™ts √† √™tre consomm√©s par les algorithmes de trading.

    Les donn√©es propres de la couche Argent sont lues.

    Des r√®gles m√©tier et des calculs complexes sont appliqu√©s :

        Calcul d'indicateurs techniques (Moyennes Mobiles, RSI, etc.) via Polars.

        Jointures avec d'autres sources de donn√©es (ex: donn√©es macro-√©conomiques) via DuckDB.

        Cr√©ation de signaux de trading bas√©s sur les strat√©gies d√©finies.

    Les tables finales, enrichies et souvent agr√©g√©es, sont stock√©es dans la couche Or.

√âtape 4 : Consommation et Analyse (Or ‚Üí Jupyter)

La couche Or est le point d'entr√©e pour toute analyse.

    Les Jupyter Notebooks se connectent directement aux tables de la couche Or via DuckDB pour explorer les donn√©es, visualiser les r√©sultats, et it√©rer rapidement sur le backtesting des strat√©gies.

‚ú® Bonnes Pratiques et Recommandations

Pour garantir la robustesse et la maintenabilit√© de la plateforme, les principes suivants sont appliqu√©s :

    Format de Fichiers : Le format Parquet est utilis√© syst√©matiquement apr√®s l'ingestion initiale pour b√©n√©ficier de la compression, du stockage en colonnes et de l'optimisation des lectures (predicate pushdown).

    Qualit√© des Donn√©es : Des m√©triques de qualit√© sont calcul√©es et suivies lors du passage √† la couche Argent pour garantir la fiabilit√© des analyses en aval.

    Versioning : Chaque couche (donn√©es) et chaque transformation (code) doit √™tre versionn√©e. Cela permet de garantir la reproductibilit√© des exp√©riences et des backtests.

    S√©paration des Environnements : Les donn√©es utilis√©es pour le backtesting (couche Or) doivent √™tre distinctes de celles utilis√©es en production pour √©viter tout biais ou contamination des mod√®les.

    Tra√ßabilit√© : Chaque table de la couche Or doit pouvoir √™tre trac√©e jusqu'√† sa source brute dans les fichiers NFS, en documentant toutes les transformations interm√©diaires.


















# Hermes
Data Lab : exploration 
---

          +-------------------------+
          |         NFS             |
          |  Fichiers bruts .zip    |
          | (API ou t√©l√©charg√©s)    |
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |        Bronze           |
          | - Tables brutes         |
          | - Partitionn√©es (date)  |
          | - Stockage : MinIO  (format Parquet)    |
          | - Lecture/√©criture :   |
          |   Polars / DuckDB       |
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |        Argent  
          Tables Bronze         |
          | - Nettoyage / structuration |
          | - Dates lisibles, alignement |
          |   temporel, types coh√©rents,contr√¥les   qualit√©   |
          | - Stockage : MinIO           |
          | - Traitement : Polars / DuckDB|
          +-----------+-------------+
                      |
                      v
          +-------------------------+
          |         Or              |
          | - Tables Argent enrichies,     |
          |   pr√™tes pour trading   |
          | - Application strat√©gie |
          | - Stockage : MinIO      |
          | - Analyse : Polars / DuckDB / Jupyter |
          +-------------------------+


| Couche        | MinIO                   | DuckDB                           | Polars                               | Jupyter Notebook                            |
| ------------- | ----------------------- | -------------------------------- | ------------------------------------ | ------------------------------------------- |
| Bronze        | Stockage partitionn√©    | Lecture rapide, SQL sur fichiers | Chargement / transformations rapides | Exploration des donn√©es                     |
| Argent        | Stockage structur√©      | SQL + Joins, agr√©gations         | Transformations complexes, nettoyage | Notebooks pour test / ETL                   |
| Or (datamart) | Stockage tables finales | Interrogation pour backtesting   | Calcul indicateurs, signaux          | Analyse / visualisation / strat√©gie trading |


Ingestion NFS ‚Üí Bronze :

Tu prends les .zip de l‚ÄôAPI, tu les d√©compresses et tu stockes les fichiers bruts sur MinIO.

DuckDB et Polars permettent de charger les fichiers Parquet/CSV directement depuis MinIO pour traitement.

Bronze ‚Üí Argent :

Nettoyage minimal et transformation structurelle : date lisible, alignement temporel, types corrects.

Polars est tr√®s rapide pour les transformations colonne par colonne.

Argent ‚Üí Or (Datamart) :

Application des r√®gles de trading et calcul des indicateurs.

DuckDB permet des jointures SQL complexes si n√©cessaire.

Polars sert pour le calcul vectoris√© tr√®s rapide (ex : indicateurs techniques).

Or ‚Üí Consommation / Analyse :

Jupyter pour visualisation et exploration.

Tu peux it√©rer sur strat√©gies de trading directement sur les tables Or.


Chaque couche peut avoir un versioning pour tracer les changements.
Bronze = ‚Äúraw‚Äù, Argent = ‚Äúcurated / structured‚Äù, Or = ‚Äúconsommable / ready-to-use‚Äù


NFS : fichiers bruts .zip en provenance de l‚ÄôAPI

Positif :

Stocker les fichiers bruts tels quels est une bonne pratique pour reproduire l‚Äôingestion initiale et conserver l‚Äôhistorique exact des donn√©es.

Permet de refaire des transformations si n√©cessaire.

√Ä am√©liorer :

V√©rifie que tu as un m√©canisme de tracking de version/date pour ces fichiers, afin de pouvoir retracer exactement quelle version a √©t√© ing√©r√©e.

Penser √† l‚Äôarchivage et nettoyage automatique si le volume devient tr√®s important.

2Ô∏è‚É£ Bronze : tables brutes partitionn√©es sur MinIO

Positif :

Partitionner d√®s le d√©part (par date par exemple) est excellent pour le scaling et l‚Äôoptimisation des lectures dans Spark ou PySpark.

Stocker sur MinIO (S3-like) est tr√®s adapt√© pour un datalake.

√Ä am√©liorer :

Assure-toi que les formats sont optimis√©s pour le traitement : Parquet ou Delta Lake (plut√¥t que CSV/JSON), pour b√©n√©ficier de compression, schema evolution, predicate pushdown.

Bronze doit rester ‚Äúraw‚Äù : √©vite de faire des transformations ici (m√™me minimes), sauf nettoyage obligatoire pour ingestion.

3Ô∏è‚É£ Argent : tables de Bronze avec transformations structurelles

Positif :

Transformation pour rendre la date lisible et alignement temporel sont classiques pour la couche ‚Äúsilver‚Äù.

Ici, on commence √† corriger/structurer les donn√©es sans perte d‚Äôinformation.

√Ä am√©liorer :

Documente bien toutes les transformations, surtout si elles influencent les calculs de strat√©gie.

Penser √† inclure des indicateurs de qualit√© / anomalies d√©tect√©es, tr√®s important en trading.

4Ô∏è‚É£ Or : tables d‚ÄôArgent avec application de strat√©gie trading

Positif :

Bonne pratique d‚Äôavoir une couche finale ‚Äúready-to-use‚Äù pour les algos de trading.

Id√©alement, ces tables sont aggr√©g√©es, filtr√©es, enrichies, et pr√™tes pour l‚Äôanalytics ou la production.

√Ä am√©liorer :

S√©pare √©ventuellement les donn√©es utilis√©es pour backtesting vs celles pour production pour √©viter les contaminations.

Penser √† des m√©ta-donn√©es de version de strat√©gie et des logs de backtest pour audit et tra√ßabilit√©.

‚úÖ Conclusion g√©n√©rale

Ton architecture suit globalement les bonnes pratiques du datalake en 3 couches (bronze/silver/gold) :

NFS = raw files

Bronze = ingestion brute partitionn√©e

Argent = structuration / nettoyage

Or = application m√©tier / trading

üí° Quelques conseils pour l‚Äôam√©liorer :

Utiliser Parquet/Delta Lake pour Bronze/Argent/Or pour performance et fiabilit√©.

Ajouter un syst√®me de versioning/metadata √† chaque couche.

Tracker la qualit√© des donn√©es √† la couche Argent.

S√©parer backtesting et production pour Or.